## 各个mq的比较  *****

### RabbitMQ

RabbitMQ 开始是用在电信业务的可靠通信的，也是少有的几款支持AMQP协议的产品之一。

优点：

1、轻量级，快速，部署使用方便
2、支持灵活的路由配置。RabbitMQ中，在生产者和队列之间有一个交换器模块。根据配置的路由规则，生产者发送的消息可以发送到不同的队列中。路由规则很灵活，还可以自己实现。
3、RabbitMQ的客户端支持大多数的编程语言。

缺点：

1、如果有大量消息堆积在队列中，性能会急剧下降
2、RabbitMQ的性能在Kafka和RocketMQ中是最差的，每秒处理几万到几十万的消息。如果应用要求高的性能，不要选择RabbitMQ。
3、RabbitMQ是Erlang开发的，功能扩展和二次开发代价很高。

---

### RocketMQ

RocketMQ 是一个开源的消息队列，使用 java 实现。借鉴了 Kafka 的设计并做了很多改进。

优点：

1、RocketMQ 主要用于有序，事务，流计算，消息推送，日志流处理，binlog分发等场景。经过了历次的双11考验，性能，稳定性可可靠性没的说。
2、RocketMQ 几乎具备了消息队列应该具备的所有特性和功能。
3、java 开发，阅读源代码、扩展、二次开发很方便。
4、对电商领域的响应延迟做了很多优化。在大多数情况下，响应在毫秒级。如果应用很关注响应时间，可以使用RocketMQ。
5、性能比RabbitMQ高一个数量级，每秒处理几十万的消息。

缺点：

1、跟周边系统的整合和兼容不是很好。

---

### Kafka

Kafka的可靠性，稳定性和功能特性基本满足大多数的应用场景。跟周边系统的兼容性是数一数二的，尤其是大数据和流计算领域，几乎所有相关的开源软件都支持Kafka。Kafka是Scala和Java开发的，对批处理和异步处理做了大量的设计，因此Kafka可以得到非常高的性能。它的异步消息的发送和接收是三个中最好的，但是跟RocketMQ拉不开数量级，每秒处理几十万的消息。如果是异步消息，并且开启了压缩，Kafka最终可以达到每秒处理2000w消息的级别。

优点：

1、支持多个生产者和消费者
2、支持broker的横向拓展
3、副本集机制，实现数据冗余，保证数据不丢失
4、通过topic将数据进行分类
5、通过分批发送压缩数据的方式，减少数据传输开销，提高吞高量
6、支持多种模式的消息
7、基于磁盘实现数据的持久化
8、高性能的处理信息，在大数据的情况下，可以保证亚秒级的消息延迟
9、一个消费者可以支持多种topic的消息
10、对CPU和内存的消耗比较小
11、对网络开销也比较小
12、支持跨数据中心的数据复制
13、支持镜像集群

缺点：

1、由于是批量发送，所以数据达不到真正的实时
2、对于mqtt协议不支持
3、不支持物联网传感数据直接接入
4、只能支持统一分区内消息有序，无法实现全局消息有序
5、监控不完善，需要安装插件
6、需要配合zookeeper进行元数据管理
7、会丢失数据，并且不支持事务
8、可能会重复消费数据，消息会乱序，可用保证一个固定的partition内部的消息是有序的，但是一个topic有多个partition的话，就不能保证有序了，需要zookeeper的支持，topic一般需要人工创建，部署和维护一般都比mq高

---

## Kafka

### 特性
1. **高吞吐量、低延迟**   每秒处理几十万消息
2. **可扩展性**    集群支持热扩展
3. **持久性、可靠性**    消息被持久化到磁盘，并且支持备份防止数据丢失
4. **容错性**    允许节点失败
5. **高并发**    支持数千个客户端同时读写


内部原理？工作流程？

1. **Producer** : 消息生产者，就是向kafka broker发消息的客户端；
2. **Consumer** : 消息消费者，向kafka broker取消息的客户端;
3. **Topic** : 可以理解为一个队列, 消息的分类。
4. **Broker** : 一台kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic；
5. **Partition** : 为了实现扩展性，一个非常大的topic可以分布到多个broker（即服务器）上，一个topic可以分为多个partition，每个partition是一个有序的队列。partition中的每条消息都会被分配一个有序的id（offset）。kafka只保证按一个partition中的顺序将消息发给consumer，不保证一个topic的整体（多个partition间）的顺序；
6. **Replication** 每一个分区都有多个副本，副本的作用是做备胎。当主分区（Leader）故障的时候会选择一个备胎（Follower）上位，成为Leader。在kafka中默认副本的最大数量是10个，且副本的数量不能大于Broker的数量，follower和leader绝对是在不同的机器，同一机器对同一个分区也只可能存放一个副本（包括自己）。
7. **Offset**：kafka的存储文件都是按照offset.kafka来命名，用offset做名字的好处是方便查找。例如你想找位于2049的位置，只要找到2048.kafka的文件即可。当然the first offset就是00000000000.kafka。
8. **Consumer Group** （CG）：这是kafka用来实现一个topic消息的广播（发给所有的consumer）和单播（发给任意一个consumer）的手段。一个topic可以有多个CG。topic的消息会复制（不是真的复制，是概念上的）到所有的CG，但每个partion只会把消息发给该CG中的一个consumer。如果需要实现广播，只要每个consumer有一个独立的CG就可以了。要实现单播只要所有的consumer在同一个CG。用CG还可以将consumer进行自由的分组而不需要多次发送消息到不同的topic； **各个consumer可以组成一个组，每个消息只能被组中的一个consumer消费，如果一个消息可以被多个consumer消费的话，那么这些consumer必须在不同的组。**


### 消息写入流程
![](img/2021-04-29-16-14-22.png)

除了消息顺序追加、页缓存等技术，Kafka 还使用零拷贝技术来进一步提升性能。所谓的零拷贝是指将数据直接从磁盘文件复制到网卡设备中，而不需要经由应用程序之手。零拷贝大大提高了应用程序的性能，减少了内核和用户模式之间的上下文切换。对 Linux 操作系统而言，零拷贝技术依赖于底层的 sendfile() 方法实现。对应于 Java 语言，FileChannal.transferTo() 方法的底层实现就是 sendfile() 方法。


### broker 副本同步？？ isr ack？？


## 重复消费

避免

## 消息丢失

### 怎么解决消息不丢失

## 消息重试

## mq如何保证顺序

kafka同一个partition下的场景，可以保证FIFO的顺序。不同partition之间不能保证顺序。多partition下无法保障消息的顺序性

Kafka 中发送1条消息的时候，可以指定(topic, partition, key) 3个参数。partiton 和 key 是可选的。如果你指定了 partition，那就是所有消息发往同1个 partition，就是有序的。并且在消费端，Kafka 保证，1个 partition 只能被1个 consumer 消费。或者你指定 key（比如 order id），具有同1个 key 的所有消息，会发往同1个 partition。也是有序的。


## 消息积压

## mq持久化










---

### 怎么实现 Exactly-Once  恰好一次

> exactly-once定义为: 不管在处理的时候是否有错误发生，计算的结果（包括所有所改变的状态）都一样。

要么都做，要么都不做。做什么呢？体现在：（1）写出所有的计算结果 （计算结果写入到kafka指定的topic中）.（2）所有状态的更新。（3）把输入的消息标记为已消费（这里的输入数据理解为kafka的消费者从broker中pull数据）。对上面这三个，kafka使用另一种具有相同语义的方式表示，分别为：（1）将计算结果写入输出topic中（2）把更新操作写入“更新日志changelog”中（注意，操作的状态能够根据“更新日志”进行回滚，类似于MySQL的更新日志，这个有别于普通的系统操作日志）（3）把消费的消息偏移量写入相应的topic中。这也就是Apache Kafka实现“要么都做，要么都不做”和exactly-once的总体设计思路。
